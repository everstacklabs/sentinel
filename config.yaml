# Sentinel Configuration
# Used as the default config. Override with --config or environment variables.

# Path to the model-catalog directory (relative or absolute)
catalog_path: "../model-catalog"

# Cache settings
cache_dir: "~/.cache/sentinel"
cache_ttl: "1h"

# Providers to sync
providers:
  - openai
  - anthropic
  - google
  - mistral
  - perplexity   # docs-only, no API key needed
  - ai21         # docs-only, no API key needed

# Source types to use for discovery
sources:
  - api
  - docs

# Dry run mode: show changes without writing
dry_run: false

# Disable caching
no_cache: false

# Risk mode: "strict" (default) or "relaxed"
risk_mode: "strict"

# Log level: debug, info, warn, error
log_level: "info"

# GitHub settings (for PR creation)
github:
  # token: set via GITHUB_TOKEN env var
  owner: "midfusionlabs"
  repo: "model-catalog"
  base_branch: "main"

# Diff settings
diff:
  track_display_name: false

# Health check settings
health:
  enabled: true
  threshold: 0.90

# OpenAI settings
openai:
  # api_key: set via OPENAI_API_KEY env var
  base_url: "https://api.openai.com/v1"

# Anthropic settings
anthropic:
  # api_key: set via ANTHROPIC_API_KEY env var
  base_url: "https://api.anthropic.com/v1"

# Google/Gemini settings
google:
  # api_key: set via GEMINI_API_KEY env var
  base_url: "https://generativelanguage.googleapis.com/v1beta"

# Mistral settings
mistral:
  # api_key: set via MISTRAL_API_KEY env var
  base_url: "https://api.mistral.ai/v1"

# LLM-as-Judge settings
judge:
  enabled: false
  provider: "anthropic"
  model: "claude-sonnet-4-20250514"
  on_reject: "draft"
  max_tokens: 4096
